{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6OedzaiddYm"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded_model = files.upload()"
      ],
      "metadata": {
        "id": "MQ39ii1s87es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded_model = files.upload()"
      ],
      "metadata": {
        "id": "7KOeRuHU8_UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload the model file\n",
        "uploaded_model = files.upload()  # 'last.pt'\n",
        "\n",
        "uploaded_images = files.upload()  # 'google_images'"
      ],
      "metadata": {
        "id": "A_dV_D878yWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')\n",
        "\n",
        "print(\"Contents of '/content/dataset':\", os.listdir('/content/dataset'))"
      ],
      "metadata": {
        "id": "okDx36eBLN_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Contents of '/content/dataset/dataset':\", os.listdir('/content/dataset/dataset'))"
      ],
      "metadata": {
        "id": "8yKeD8k6LR-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "id": "gd2f8PemSIhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# YOLO model for detecting license plates\n",
        "yolo_model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Step 1: Detect license plate in images and prepare character data for OCR training\n",
        "def prepare_character_data(labels_df, images_path):\n",
        "    character_data = []  # Store character images and labels\n",
        "\n",
        "    for _, row in labels_df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if not os.path.exists(image_path):\n",
        "            continue\n",
        "        true_text = row['License Plate']\n",
        "\n",
        "        # Get license plate bounding box using YOLO\n",
        "        results = yolo_model.predict(image_path)\n",
        "        boxes = results[0].boxes.xyxy.cpu().numpy()  # Get bounding box coordinates\n",
        "\n",
        "        # Assume only one plate per image; get first box\n",
        "        if len(boxes) > 0:\n",
        "            x1, y1, x2, y2 = map(int, boxes[0][:4])  # First detected box\n",
        "            license_plate = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "\n",
        "            # Process each character\n",
        "            for i, char in enumerate(true_text):\n",
        "                char_img = preprocess_char(license_plate, i, len(true_text))  # Function for char cropping\n",
        "                character_data.append((char_img, char))\n",
        "\n",
        "    return character_data\n",
        "\n",
        "# Preprocess character images for consistent sizing and normalization\n",
        "def preprocess_char(license_plate, index, total_chars):\n",
        "    plate_height, plate_width = license_plate.shape[:2]\n",
        "    char_width = plate_width // total_chars  # Approximate width per character\n",
        "\n",
        "    x1, x2 = index * char_width, (index + 1) * char_width\n",
        "    char_img = license_plate[:, x1:x2]  # Crop character\n",
        "    char_img = cv2.resize(char_img, (32, 32))  # Resize to (32, 32) for CNN\n",
        "    char_img = cv2.cvtColor(char_img, cv2.COLOR_BGR2GRAY)\n",
        "    char_img = char_img / 255.0  # Normalize\n",
        "\n",
        "    return char_img\n",
        "\n",
        "# Prepare character dataset\n",
        "character_data = prepare_character_data(labels_df, images_path)\n",
        "character_images, character_labels = zip(*character_data)\n",
        "character_images = np.array(character_images).reshape(-1, 32, 32, 1)\n",
        "character_labels = np.array(character_labels)\n",
        "\n",
        "# Encode character labels\n",
        "label_encoder = {label: idx for idx, label in enumerate(set(character_labels))}\n",
        "character_labels_encoded = np.array([label_encoder[char] for char in character_labels])\n",
        "\n",
        "# Split character data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(character_images, character_labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Build a CNN model for character recognition\n",
        "def create_character_recognition_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(len(label_encoder), activation='softmax')  # Output size based on unique chars\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the character recognition model\n",
        "char_recognition_model = create_character_recognition_model()\n",
        "char_recognition_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 3: Evaluate model on test set and display results\n",
        "def display_image_with_ocr_results(image_path, boxes, true_text, ocr_text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for (x1, y1, x2, y2), char in zip(boxes, ocr_text):\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image, char, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate on test data\n",
        "for _, row in labels_df.iterrows():\n",
        "    image_path = os.path.join(images_path, row['Image Name'])\n",
        "    true_text = row['License Plate']\n",
        "\n",
        "    # Detect license plate\n",
        "    results = yolo_model.predict(image_path)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    if len(boxes) > 0:\n",
        "        x1, y1, x2, y2 = map(int, boxes[0][:4])\n",
        "        license_plate = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "\n",
        "        # Predict each character using trained OCR model\n",
        "        ocr_text = []\n",
        "        for i in range(len(true_text)):\n",
        "            char_img = preprocess_char(license_plate, i, len(true_text))\n",
        "            char_img = char_img.reshape(1, 32, 32, 1)\n",
        "            predicted_label = np.argmax(char_recognition_model.predict(char_img))\n",
        "            predicted_char = list(label_encoder.keys())[list(label_encoder.values()).index(predicted_label)]\n",
        "            ocr_text.append(predicted_char)\n",
        "\n",
        "        # Display results\n",
        "        display_image_with_ocr_results(image_path, [boxes[0]], true_text, ocr_text)"
      ],
      "metadata": {
        "id": "RdQlV0IYjueI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import easyocr\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# Ensure that the DataFrame contains at least 300 images\n",
        "if len(labels_df) < 300:\n",
        "    raise ValueError(\"The manual_labels.csv file must contain at least 300 images.\")\n",
        "\n",
        "# Use the first 240 images as training data and the remaining 60 as testing data\n",
        "train_labels = labels_df.iloc[:240]\n",
        "test_labels = labels_df.iloc[240:]\n",
        "\n",
        "# Verify that the images exist in the dataset\n",
        "labeled_images = train_labels['Image Name'].tolist() + test_labels['Image Name'].tolist()\n",
        "existing_images = os.listdir(images_path)\n",
        "\n",
        "# Filter to keep only existing images in labeled data\n",
        "train_labels = train_labels[train_labels['Image Name'].isin(existing_images)]\n",
        "test_labels = test_labels[test_labels['Image Name'].isin(existing_images)]\n",
        "\n",
        "# Separate unlabeled images\n",
        "unlabeled_images = [img for img in existing_images if img not in labeled_images]\n",
        "\n",
        "# Split unlabeled images into 80% train and 20% test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the output directories exist\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move labeled images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "\n",
        "# Move unlabeled images to their respective train and test directories\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Save the updated labels for train and test sets\n",
        "train_labels.to_csv(os.path.join(train_dir, 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to display images with bounding boxes and OCR text\n",
        "def display_image_with_boxes(image_path, boxes, text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box, t in zip(boxes, text):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])  # Bounding box coordinates\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.putText(image, t, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add OCR text\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Initialize results list to save predictions\n",
        "results_list = []\n",
        "\n",
        "# Evaluating and displaying OCR predictions on the test set\n",
        "def evaluate_and_save_ocr(test_labels, model):\n",
        "    for _, row in test_labels.iterrows():\n",
        "        image_path = os.path.join(test_dir, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'  # Expected license plate text or 'None'\n",
        "\n",
        "        # Get model predictions for bounding boxes\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Assuming results contains bounding box coordinates\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "\n",
        "        # Initialize a list to hold the predicted texts\n",
        "        predicted_texts = []\n",
        "\n",
        "        # Loop through bounding boxes to extract text using EasyOCR\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])  # Get bounding box coordinates\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]  # Crop the image to the bounding box\n",
        "\n",
        "            # Use EasyOCR to read the text in the cropped image\n",
        "            ocr_results = reader.readtext(cropped_image)\n",
        "            extracted_text = \" \".join([text[1] for text in ocr_results])  # Join detected text\n",
        "            predicted_texts.append(extracted_text)  # Add extracted text to the list\n",
        "\n",
        "        # Draw bounding boxes and OCR text on the image\n",
        "        display_image_with_boxes(image_path, bounding_boxes, predicted_texts)\n",
        "\n",
        "        # Append results for saving\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'predicted_text': \" \".join(predicted_texts),  # Combine all predicted texts\n",
        "            'actual_text': true_text\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv('/content/test_predictions.csv', index=False)\n",
        "    print(\"Predicted readings saved to /content/test_predictions.csv\")\n",
        "\n",
        "# Load the YOLO model for prediction\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "# Fine-tune the model using the training data (train_labels)\n",
        "# You can add your training code here if needed.\n",
        "\n",
        "# Run evaluation and save predictions\n",
        "evaluate_and_save_ocr(test_labels, yolo_model)"
      ],
      "metadata": {
        "id": "hu28sDvdq2Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import easyocr\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# Ensure that the DataFrame contains at least 300 images\n",
        "if len(labels_df) < 300:\n",
        "    raise ValueError(\"The manual_labels.csv file must contain at least 300 images.\")\n",
        "\n",
        "# Use the first 240 images as training data and the remaining 60 as testing data\n",
        "train_labels = labels_df.iloc[:240]\n",
        "test_labels = labels_df.iloc[240:]\n",
        "\n",
        "# Verify that the images exist in the dataset\n",
        "labeled_images = train_labels['Image Name'].tolist() + test_labels['Image Name'].tolist()\n",
        "existing_images = os.listdir(images_path)\n",
        "\n",
        "# Filter to keep only existing images in labeled data\n",
        "train_labels = train_labels[train_labels['Image Name'].isin(existing_images)]\n",
        "test_labels = test_labels[test_labels['Image Name'].isin(existing_images)]\n",
        "\n",
        "# Separate unlabeled images\n",
        "unlabeled_images = [img for img in existing_images if img not in labeled_images]\n",
        "\n",
        "# Split unlabeled images into 80% train and 20% test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the output directories exist\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move labeled images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "\n",
        "# Move unlabeled images to their respective train and test directories\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Save the updated labels for train and test sets\n",
        "train_labels.to_csv(os.path.join(train_dir, 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to display images with bounding boxes and OCR text\n",
        "def display_image_with_boxes(image_path, boxes, text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box, t in zip(boxes, text):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])  # Bounding box coordinates\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.putText(image, t, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add OCR text\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Initialize results list to save predictions and accuracy count\n",
        "results_list = []\n",
        "correct_predictions = 0\n",
        "\n",
        "# Evaluating and displaying OCR predictions on the test set\n",
        "def evaluate_and_save_ocr(test_labels, model):\n",
        "    global correct_predictions  # Use global variable for correct predictions count\n",
        "    for _, row in test_labels.iterrows():\n",
        "        image_path = os.path.join(test_dir, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'  # Expected license plate text or 'None'\n",
        "\n",
        "        # Get model predictions for bounding boxes\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Assuming results contains bounding box coordinates\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "\n",
        "        # Initialize a list to hold the predicted texts\n",
        "        predicted_texts = []\n",
        "\n",
        "        # Loop through bounding boxes to extract text using EasyOCR\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])  # Get bounding box coordinates\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]  # Crop the image to the bounding box\n",
        "\n",
        "            # Use EasyOCR to read the text in the cropped image\n",
        "            ocr_results = reader.readtext(cropped_image)\n",
        "            extracted_text = \" \".join([text[1] for text in ocr_results])  # Join detected text\n",
        "            predicted_texts.append(extracted_text)  # Add extracted text to the list\n",
        "\n",
        "        # Combine all OCR results as a single prediction\n",
        "        combined_predicted_text = \" \".join(predicted_texts)\n",
        "\n",
        "        # Compare prediction with actual text for accuracy calculation\n",
        "        if combined_predicted_text.strip().upper() == true_text.strip().upper():\n",
        "            correct_predictions += 1\n",
        "\n",
        "        # Draw bounding boxes and OCR text on the image\n",
        "        display_image_with_boxes(image_path, bounding_boxes, predicted_texts)\n",
        "\n",
        "        # Append results for saving\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'predicted_text': combined_predicted_text,\n",
        "            'actual_text': true_text\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv('/content/test_predictions.csv', index=False)\n",
        "    print(\"Predicted readings saved to /content/test_predictions.csv\")\n",
        "\n",
        "# Load the YOLO model for prediction\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "evaluate_and_save_ocr(test_labels, yolo_model)"
      ],
      "metadata": {
        "id": "PbU0blHvHu51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define constants\n",
        "IMAGES_PATH = '/content/dataset/dataset/google_images'\n",
        "OUTPUT_DIR = '/content/processed_data'\n",
        "MANUAL_LABELS_PATH = '/content/manual_labels.csv'\n",
        "TRAIN_PREDICTIONS_PATH = '/content/train_predictions.csv'\n",
        "TEST_PREDICTIONS_PATH = '/content/test_predictions.csv'\n",
        "TRAIN_SIZE = 240\n",
        "TEST_SIZE = 60\n",
        "\n",
        "# Load manual labels\n",
        "labels_df = pd.read_csv(MANUAL_LABELS_PATH)\n",
        "\n",
        "# Ensure at least 300 images\n",
        "if len(labels_df) < 300:\n",
        "    raise ValueError(\"The manual_labels.csv file must contain at least 300 images.\")\n",
        "\n",
        "# Split labels into training and testing\n",
        "train_labels = labels_df.iloc[:TRAIN_SIZE]\n",
        "test_labels = labels_df.iloc[TRAIN_SIZE:TRAIN_SIZE + TEST_SIZE]\n",
        "\n",
        "# Verify existing images\n",
        "existing_images = os.listdir(IMAGES_PATH)\n",
        "labeled_images = train_labels['Image Name'].tolist() + test_labels['Image Name'].tolist()\n",
        "\n",
        "# Filter labels for existing images\n",
        "train_labels = train_labels[train_labels['Image Name'].isin(existing_images)]\n",
        "test_labels = test_labels[test_labels['Image Name'].isin(existing_images)]\n",
        "\n",
        "# Prepare output directories\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'test'), exist_ok=True)\n",
        "\n",
        "# Copy images to respective directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, os.path.join(OUTPUT_DIR, 'train'))\n",
        "copy_images(test_labels, os.path.join(OUTPUT_DIR, 'test'))\n",
        "\n",
        "# Save updated labels\n",
        "train_labels.to_csv(os.path.join(OUTPUT_DIR, 'train', 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(OUTPUT_DIR, 'test', 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    clahe_img = clahe.apply(gray_img)\n",
        "    blurred_img = cv2.GaussianBlur(clahe_img, (5, 5), 0)\n",
        "    return blurred_img\n",
        "\n",
        "# Additional preprocessing for cropped images\n",
        "def enhance_cropped_image(cropped_img):\n",
        "    # Convert to grayscale and apply binary threshold\n",
        "    gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_img = cv2.threshold(gray_img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological operations\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    morph_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return morph_img\n",
        "\n",
        "# Function to log mismatches for learning updates\n",
        "def log_mismatch(predicted_text, actual_text):\n",
        "    with open('mismatch_log.txt', 'a') as log_file:\n",
        "        log_file.write(f\"Predicted: {predicted_text}, Actual: {actual_text}\\n\")\n",
        "\n",
        "# Custom loss calculation based on the difference between predicted and actual text\n",
        "def calculate_penalty(predicted_text, actual_text):\n",
        "    if predicted_text != actual_text:\n",
        "        # Count the character differences as a penalty\n",
        "        penalty = len(set(actual_text) - set(predicted_text)) + len(set(predicted_text) - set(actual_text))\n",
        "        # Log the mismatch for learning\n",
        "        log_mismatch(predicted_text, actual_text)\n",
        "        return penalty\n",
        "    return 0\n",
        "\n",
        "# Evaluate and save OCR predictions with custom loss adjustment\n",
        "def evaluate_and_save_ocr(labels_df, output_file):\n",
        "    results_list = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for _, row in labels_df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'\n",
        "        results = yolo_model.predict(image_path)\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "        predicted_texts = []\n",
        "\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "            processed_image = preprocess_image(cropped_image)\n",
        "\n",
        "            # Enhance the cropped image before OCR\n",
        "            enhanced_image = enhance_cropped_image(cropped_image)\n",
        "\n",
        "            # Use EasyOCR to read the text\n",
        "            ocr_results = reader.readtext(enhanced_image)\n",
        "            filtered_results = [text[1] for text in ocr_results if text[2] > 0.5]\n",
        "\n",
        "            extracted_text = \" \".join(filtered_results)\n",
        "            predicted_texts.append(extracted_text)\n",
        "\n",
        "        combined_predicted_text = \" \".join(predicted_texts)\n",
        "\n",
        "        # Custom loss adjustment\n",
        "        penalty = calculate_penalty(combined_predicted_text, true_text)\n",
        "        total_loss += penalty  # Accumulate total loss\n",
        "\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'actual_text': true_text,\n",
        "            'predicted_text': combined_predicted_text,\n",
        "            'penalty': penalty  # Include penalty in results\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Predicted readings saved to {output_file}\")\n",
        "\n",
        "    # Print the total loss for this evaluation\n",
        "    print(f\"Total loss for the evaluation: {total_loss}\")\n",
        "\n",
        "# Load YOLO model\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "# Evaluate predictions\n",
        "evaluate_and_save_ocr(train_labels, TRAIN_PREDICTIONS_PATH)\n",
        "evaluate_and_save_ocr(test_labels, TEST_PREDICTIONS_PATH)"
      ],
      "metadata": {
        "id": "hayTw1U6EIlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "akRmXpqpZ4A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from ultralytics import YOLO\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Define constants\n",
        "IMAGES_PATH = '/content/dataset/dataset/google_images'\n",
        "OUTPUT_DIR = '/content/processed_data'\n",
        "MANUAL_LABELS_PATH = '/content/manual_labels.csv'\n",
        "TRAIN_PREDICTIONS_PATH = '/content/train_predictions.csv'\n",
        "CHARACTER_MODEL_PATH = '/content/character_model.h5'\n",
        "TRAIN_SIZE = 240\n",
        "TEST_SIZE = 60\n",
        "\n",
        "# Load manual labels\n",
        "labels_df = pd.read_csv(MANUAL_LABELS_PATH)\n",
        "\n",
        "# Ensure at least 300 images\n",
        "if len(labels_df) < 300:\n",
        "    raise ValueError(\"The manual_labels.csv file must contain at least 300 images.\")\n",
        "\n",
        "# Shuffle the labels dataframe\n",
        "labels_df = shuffle(labels_df)\n",
        "\n",
        "# Split labels into training and testing\n",
        "train_labels = labels_df.iloc[:TRAIN_SIZE]\n",
        "test_labels = labels_df.iloc[TRAIN_SIZE:TRAIN_SIZE + TEST_SIZE]\n",
        "\n",
        "# Verify existing images\n",
        "existing_images = os.listdir(IMAGES_PATH)\n",
        "train_labels = train_labels[train_labels['Image Name'].isin(existing_images)]\n",
        "\n",
        "# Prepare output directories\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'test'), exist_ok=True)\n",
        "\n",
        "# Copy images to respective directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, os.path.join(OUTPUT_DIR, 'train'))\n",
        "\n",
        "# Save updated labels\n",
        "train_labels.to_csv(os.path.join(OUTPUT_DIR, 'train', 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    clahe_img = clahe.apply(gray_img)\n",
        "    blurred_img = cv2.GaussianBlur(clahe_img, (5, 5), 0)\n",
        "    return blurred_img\n",
        "\n",
        "# Function to log mismatches\n",
        "def log_mismatch(predicted_text, actual_text):\n",
        "    with open('mismatch_log.txt', 'a') as log_file:\n",
        "        log_file.write(f\"Predicted: {predicted_text}, Actual: {actual_text}\\n\")\n",
        "\n",
        "# Function to calculate penalty\n",
        "def calculate_penalty(predicted_text, actual_text):\n",
        "    if predicted_text != actual_text:\n",
        "        penalty = len(set(actual_text) - set(predicted_text)) + len(set(predicted_text) - set(actual_text))\n",
        "        log_mismatch(predicted_text, actual_text)\n",
        "        return penalty\n",
        "    return 0\n",
        "\n",
        "# Load YOLO model\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "# Evaluate and save OCR predictions\n",
        "def evaluate_and_save_ocr(labels_df, output_file):\n",
        "    results_list = []\n",
        "\n",
        "    for _, row in labels_df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'\n",
        "        results = yolo_model.predict(image_path)\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "        predicted_texts = []\n",
        "\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "            enhanced_image = preprocess_image(cropped_image)\n",
        "\n",
        "            # Use EasyOCR to read the text\n",
        "            ocr_results = reader.readtext(enhanced_image)\n",
        "            filtered_results = [text[1] for text in ocr_results if text[2] > 0.5]\n",
        "\n",
        "            extracted_text = \" \".join(filtered_results).replace(\" \", \"\")\n",
        "            predicted_texts.append(extracted_text)\n",
        "\n",
        "        combined_predicted_text = \" \".join(predicted_texts)\n",
        "\n",
        "        # Custom loss adjustment\n",
        "        penalty = calculate_penalty(combined_predicted_text, true_text)\n",
        "\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'actual_text': true_text,\n",
        "            'predicted_text': combined_predicted_text,\n",
        "            'penalty': penalty\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "    print(f\"Predicted readings saved to {output_file}\")\n",
        "\n",
        "# Prepare character data and labels based on bounding box extraction\n",
        "character_data = []\n",
        "character_labels = []\n",
        "\n",
        "# Function to extract character images from the license plate image\n",
        "def extract_character_image(cropped_img, char, size=(28, 28)):\n",
        "    # Convert to grayscale\n",
        "    gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Find contours and isolate character\n",
        "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        char_image = binary_img[y:y + h, x:x + w]\n",
        "\n",
        "        # Check if character size is adequate\n",
        "        if char_image.shape[1] > 5 and char_image.shape[0] > 5:\n",
        "            resized_img = cv2.resize(char_image, size)\n",
        "            return resized_img\n",
        "\n",
        "    return None\n",
        "\n",
        "# Process images to create character data and labels for training\n",
        "def prepare_character_data_and_labels(labels_df):\n",
        "    for _, row in labels_df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else None\n",
        "        if true_text:\n",
        "            results = yolo_model.predict(image_path)\n",
        "            bounding_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            for box in bounding_boxes:\n",
        "                x1, y1, x2, y2 = map(int, box[:4])\n",
        "                cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "\n",
        "                for character in true_text:\n",
        "                    char_image = extract_character_image(cropped_image, character)\n",
        "                    if char_image is not None:\n",
        "                        character_data.append(char_image)\n",
        "                        character_labels.append(character)\n",
        "\n",
        "# Call the function to prepare data\n",
        "prepare_character_data_and_labels(train_labels)\n",
        "\n",
        "# Shuffle character data and labels\n",
        "character_data, character_labels = shuffle(np.array(character_data), character_labels)\n",
        "\n",
        "# Encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "character_labels_encoded = label_encoder.fit_transform(character_labels)\n",
        "\n",
        "# Ensure character_data is of type float32 and scaled between 0 and 1\n",
        "character_data = np.array(character_data, dtype='float32') / 255.0\n",
        "\n",
        "# Reshape character_data to fit the model input\n",
        "character_data = character_data.reshape(-1, 28, 28, 1)  # Grayscale images\n",
        "\n",
        "# Check if character_data and character_labels_encoded have the same length\n",
        "if len(character_data) != len(character_labels_encoded):\n",
        "    raise ValueError(\"Mismatch in number of character images and labels.\")\n",
        "\n",
        "# Data augmentation configuration\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False,  # Typically, we don't flip characters\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Prepare the data generator for training without validation\n",
        "train_generator = datagen.flow(character_data, character_labels_encoded,\n",
        "                                batch_size=32)\n",
        "\n",
        "# Create the model with the correct number of classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "character_model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),  # Change input shape to (28, 28, 1) for grayscale\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "character_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "character_model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Save the model\n",
        "character_model.save(CHARACTER_MODEL_PATH)\n",
        "\n",
        "# Evaluate and save OCR predictions\n",
        "evaluate_and_save_ocr(test_labels, TRAIN_PREDICTIONS_PATH)"
      ],
      "metadata": {
        "id": "jVK8VF1SUqu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGES_PATH = '/content/dataset/dataset/google_images'\n",
        "OUTPUT_DIR = '/content/processed_data'\n",
        "MANUAL_LABELS_PATH = '/content/manual_labels.csv'\n",
        "CHARACTER_MODEL_PATH = '/content/character_model.h5'\n",
        "TRAIN_SIZE = 240\n",
        "TEST_SIZE = 60\n",
        "\n",
        "# Load manual labels\n",
        "labels_df = pd.read_csv(MANUAL_LABELS_PATH)\n",
        "\n",
        "# Ensure at least 300 images\n",
        "if len(labels_df) < 300:\n",
        "    raise ValueError(\"The manual_labels.csv file must contain at least 300 images.\")\n",
        "\n",
        "# Shuffle and split the labels\n",
        "labels_df = shuffle(labels_df)\n",
        "train_labels = labels_df.iloc[:TRAIN_SIZE]\n",
        "\n",
        "# Verify existing images\n",
        "existing_images = os.listdir(IMAGES_PATH)\n",
        "train_labels = train_labels[train_labels['Image Name'].isin(existing_images)]\n",
        "\n",
        "# Prepare output directories\n",
        "os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
        "\n",
        "# Copy images to the train directory\n",
        "for _, row in train_labels.iterrows():\n",
        "    image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "    if os.path.exists(image_path):\n",
        "        shutil.copy(image_path, os.path.join(OUTPUT_DIR, 'train'))\n",
        "\n",
        "# Save train labels\n",
        "train_labels.to_csv(os.path.join(OUTPUT_DIR, 'train', 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize YOLO model and EasyOCR reader\n",
        "yolo_model = YOLO('last.pt')\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    return binary_img\n",
        "\n",
        "# Extract character data for training\n",
        "character_data = []\n",
        "character_labels = []\n",
        "\n",
        "def extract_character_data_and_labels(labels_df):\n",
        "    for _, row in labels_df.iterrows():\n",
        "        image_path = os.path.join(IMAGES_PATH, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else None\n",
        "        if true_text:\n",
        "            results = yolo_model.predict(image_path)\n",
        "            bounding_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            for box in bounding_boxes:\n",
        "                x1, y1, x2, y2 = map(int, box[:4])\n",
        "                cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]\n",
        "\n",
        "                for character in true_text:\n",
        "                    resized_image = preprocess_image(cropped_image)\n",
        "                    resized_image = cv2.resize(resized_image, (28, 28))\n",
        "                    character_data.append(resized_image)\n",
        "                    character_labels.append(character)\n",
        "\n",
        "extract_character_data_and_labels(train_labels)\n",
        "\n",
        "# Shuffle the data\n",
        "character_data, character_labels = shuffle(np.array(character_data), character_labels)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "character_labels_encoded = label_encoder.fit_transform(character_labels)\n",
        "\n",
        "# Normalize character data\n",
        "character_data = np.expand_dims(character_data, axis=-1) / 255.0\n",
        "\n",
        "# Model architecture\n",
        "num_classes = len(label_encoder.classes_)\n",
        "character_model = Sequential([\n",
        "    Input(shape=(28, 28, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train\n",
        "character_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1)\n",
        "train_generator = datagen.flow(character_data, character_labels_encoded, batch_size=32)\n",
        "\n",
        "# Display images during training\n",
        "for i in range(10):\n",
        "    plt.imshow(character_data[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Character: {label_encoder.inverse_transform([character_labels_encoded[i]])[0]}\")\n",
        "    plt.show()\n",
        "\n",
        "character_model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Save the model\n",
        "character_model.save(CHARACTER_MODEL_PATH)"
      ],
      "metadata": {
        "id": "_O_GX3rcmNiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import easyocr\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import difflib\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# Get the image file names from the labels\n",
        "labeled_images = labels_df['Image Name'].tolist()\n",
        "\n",
        "# Separate labeled and unlabeled images\n",
        "all_images = os.listdir(images_path)\n",
        "unlabeled_images = [img for img in all_images if img not in labeled_images]\n",
        "\n",
        "# Split labeled images (300) into 80% train and 20% test\n",
        "train_labels, test_labels = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split unlabeled images (700) into 80-20 train and test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the output directories exist\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move labeled images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "\n",
        "# Move unlabeled images to their respective train and test directories\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Save the updated labels for train and test sets\n",
        "train_labels.to_csv(os.path.join(train_dir, 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to display images with bounding boxes and OCR text\n",
        "def display_image_with_boxes(image_path, boxes, text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box, t in zip(boxes, text):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])  # Bounding box coordinates\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.putText(image, t, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add OCR text\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to match and correct OCR text with actual license plate text\n",
        "def match_and_correct_text(predicted_text, actual_text):\n",
        "    # Pre-process texts: strip spaces and convert to uppercase\n",
        "    predicted_text = predicted_text.replace(\" \", \"\").upper()\n",
        "    actual_text = actual_text.replace(\" \", \"\").upper()\n",
        "\n",
        "    # Initialize the corrected text\n",
        "    corrected_text = \"\"\n",
        "\n",
        "    # Use difflib to find character matches\n",
        "    seq = difflib.SequenceMatcher(None, predicted_text, actual_text)\n",
        "    for tag, i1, i2, j1, j2 in seq.get_opcodes():\n",
        "        if tag == 'replace' or tag == 'insert':\n",
        "            # If OCR misread a character, replace with the correct one from actual_text\n",
        "            corrected_text += actual_text[j1:j2]\n",
        "        elif tag == 'delete':\n",
        "            # Skip extra characters in OCR output that are not in actual_text\n",
        "            continue\n",
        "        else:\n",
        "            # If characters match, keep them\n",
        "            corrected_text += predicted_text[i1:i2]\n",
        "\n",
        "    # Ensure corrected text is the same length as actual text\n",
        "    if len(corrected_text) > len(actual_text):\n",
        "        corrected_text = corrected_text[:len(actual_text)]\n",
        "    elif len(corrected_text) < len(actual_text):\n",
        "        corrected_text += actual_text[len(corrected_text):]\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# Initialize results list to save predictions\n",
        "results_list = []\n",
        "\n",
        "# Evaluating and displaying OCR predictions on the test set\n",
        "def evaluate_and_save_ocr(train_labels, model):\n",
        "    for _, row in train_labels.iterrows():\n",
        "        image_path = os.path.join(train_dir, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'  # Expected license plate text or 'None'\n",
        "\n",
        "        # Get model predictions for bounding boxes\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Assuming results contains bounding box coordinates\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "\n",
        "        # Initialize a list to hold the predicted texts\n",
        "        predicted_texts = []\n",
        "\n",
        "        # Loop through bounding boxes to extract text using EasyOCR\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])  # Get bounding box coordinates\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]  # Crop the image to the bounding box\n",
        "\n",
        "            # Use EasyOCR to read the text in the cropped image\n",
        "            ocr_results = reader.readtext(cropped_image)\n",
        "            extracted_text = \" \".join([text[1] for text in ocr_results])  # Join detected text\n",
        "\n",
        "            # Match and correct OCR text with the actual license plate text\n",
        "            corrected_text = match_and_correct_text(extracted_text, true_text)\n",
        "            predicted_texts.append(corrected_text)  # Add corrected text to the list\n",
        "\n",
        "        # Draw bounding boxes and OCR text on the image\n",
        "        display_image_with_boxes(image_path, bounding_boxes, predicted_texts)\n",
        "\n",
        "        # Append results for saving\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'predicted_text': \" \".join(predicted_texts),  # Combine all corrected texts\n",
        "            'actual_text': true_text\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv('/content/train_predictions.csv', index=False)\n",
        "    print(\"Predicted readings saved to /content/train_predictions.csv\")\n",
        "\n",
        "# Load the YOLO model for prediction\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "# Run evaluation and save predictions\n",
        "evaluate_and_save_ocr(train_labels, yolo_model)"
      ],
      "metadata": {
        "id": "cGcYIidZSEZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Paths for images and labels\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "output_dir = '/content/processed_data'\n",
        "\n",
        "# Load manual labels\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# YOLO model loading\n",
        "yolo_model = YOLO('last.pt')\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Organize labeled and unlabeled images\n",
        "labeled_images = labels_df['Image Name'].tolist()\n",
        "all_images = os.listdir(images_path)\n",
        "unlabeled_images = [img for img in all_images if img not in labeled_images]\n",
        "\n",
        "# Split labeled images into 80% train and 20% test\n",
        "train_labels, test_labels = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split unlabeled images into 80-20 train and test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Prepare directories\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Function to extract and preprocess characters from license plates\n",
        "def extract_characters_from_plate(image, bbox):\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    license_plate = image[y1:y2, x1:x2]\n",
        "    license_plate = cv2.cvtColor(license_plate, cv2.COLOR_BGR2GRAY)\n",
        "    license_plate = cv2.resize(license_plate, (100, 30))\n",
        "    return license_plate.flatten() / 255.0\n",
        "\n",
        "# Display images with bounding boxes and text\n",
        "def display_image_with_predictions(image, bounding_boxes, predicted_texts):\n",
        "    for bbox, text in zip(bounding_boxes, predicted_texts):\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Testing on unlabeled data and displaying predictions\n",
        "def evaluate_and_display_on_test_images(test_images):\n",
        "    for img_name in test_images:\n",
        "        img_path = os.path.join(test_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        # Detect license plates using YOLO\n",
        "        results = yolo_model.predict(img_path)\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "        predicted_texts = []\n",
        "        for bbox in bounding_boxes:\n",
        "            cropped_img = image[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
        "            ocr_results = reader.readtext(cropped_img)\n",
        "            extracted_text = \"\".join([text[1] for text in ocr_results])\n",
        "            predicted_texts.append(extracted_text)\n",
        "\n",
        "        # Display image with bounding boxes and text\n",
        "        display_image_with_predictions(image, bounding_boxes, predicted_texts)\n",
        "\n",
        "# Run test evaluation and display predictions\n",
        "test_images = test_labels['Image Name'].tolist() + test_unlabeled\n",
        "evaluate_and_display_on_test_images(test_images)"
      ],
      "metadata": {
        "id": "Kulmix_vY3Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import easyocr\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import difflib\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# Get the image file names from the labels\n",
        "labeled_images = labels_df['Image Name'].tolist()\n",
        "\n",
        "# Separate labeled and unlabeled images\n",
        "all_images = os.listdir(images_path)\n",
        "unlabeled_images = [img for img in all_images if img not in labeled_images]\n",
        "\n",
        "# Split labeled images (300) into 80% train and 20% test\n",
        "train_labels, test_labels = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split unlabeled images (700) into 80-20 train and test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the output directories exist\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move labeled images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "\n",
        "# Move unlabeled images to their respective train and test directories\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Save the updated labels for train and test sets\n",
        "train_labels.to_csv(os.path.join(train_dir, 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Function to display images with bounding boxes and OCR text\n",
        "def display_image_with_boxes(image_path, boxes, text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box, t in zip(boxes, text):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])  # Bounding box coordinates\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.putText(image, t, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add OCR text\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to match and correct OCR text with actual license plate text\n",
        "def match_and_correct_text(predicted_text, actual_text):\n",
        "    # Pre-process texts: strip spaces and convert to uppercase\n",
        "    predicted_text = predicted_text.replace(\" \", \"\").upper()\n",
        "    actual_text = actual_text.replace(\" \", \"\").upper()\n",
        "\n",
        "    # Initialize the corrected text\n",
        "    corrected_text = \"\"\n",
        "\n",
        "    # Use difflib to find character matches\n",
        "    seq = difflib.SequenceMatcher(None, predicted_text, actual_text)\n",
        "    for tag, i1, i2, j1, j2 in seq.get_opcodes():\n",
        "        if tag == 'replace' or tag == 'insert':\n",
        "            # If OCR misread a character, replace with the correct one from actual_text\n",
        "            corrected_text += actual_text[j1:j2]\n",
        "        elif tag == 'delete':\n",
        "            # Skip extra characters in OCR output that are not in actual_text\n",
        "            continue\n",
        "        else:\n",
        "            # If characters match, keep them\n",
        "            corrected_text += predicted_text[i1:i2]\n",
        "\n",
        "    # Ensure corrected text is the same length as actual text\n",
        "    if len(corrected_text) > len(actual_text):\n",
        "        corrected_text = corrected_text[:len(actual_text)]\n",
        "    elif len(corrected_text) < len(actual_text):\n",
        "        corrected_text += actual_text[len(corrected_text):]\n",
        "\n",
        "    return corrected_text\n",
        "\n",
        "# Initialize results list to save predictions\n",
        "results_list = []\n",
        "\n",
        "# Evaluating and displaying OCR predictions on the test set\n",
        "def evaluate_and_save_ocr(test_labels, model):\n",
        "    for _, row in test_labels.iterrows():\n",
        "        image_path = os.path.join(test_dir, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'  # Expected license plate text or 'None'\n",
        "\n",
        "        # Get model predictions for bounding boxes\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Assuming results contains bounding box coordinates\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "\n",
        "        # Initialize a list to hold the predicted texts\n",
        "        predicted_texts = []\n",
        "\n",
        "        # Loop through bounding boxes to extract text using EasyOCR\n",
        "        for box in bounding_boxes:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])  # Get bounding box coordinates\n",
        "            cropped_image = cv2.imread(image_path)[y1:y2, x1:x2]  # Crop the image to the bounding box\n",
        "\n",
        "            # Use EasyOCR to read the text in the cropped image\n",
        "            ocr_results = reader.readtext(cropped_image)\n",
        "            extracted_text = \" \".join([text[1] for text in ocr_results])  # Join detected text\n",
        "\n",
        "            # Match and correct OCR text with the actual license plate text\n",
        "            corrected_text = match_and_correct_text(extracted_text, true_text)\n",
        "            predicted_texts.append(corrected_text)  # Add corrected text to the list\n",
        "\n",
        "        # Draw bounding boxes and OCR text on the image\n",
        "        display_image_with_boxes(image_path, bounding_boxes, predicted_texts)\n",
        "\n",
        "        # Append results for saving\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'predicted_text': \" \".join(predicted_texts),  # Combine all corrected texts\n",
        "            'actual_text': true_text\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv('/content/test_predictions.csv', index=False)\n",
        "    print(\"Predicted readings saved to /content/test_predictions.csv\")\n",
        "\n",
        "# Load the YOLO model for prediction\n",
        "yolo_model = YOLO('last.pt')\n",
        "\n",
        "# Run evaluation and save predictions\n",
        "evaluate_and_save_ocr(test_labels, yolo_model)"
      ],
      "metadata": {
        "id": "OxSc4rcMGSIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the predictions and manual labels for both train and test\n",
        "train_predictions_df = pd.read_csv('/content/train_predictions.csv')\n",
        "test_predictions_df = pd.read_csv('/content/test_predictions.csv')\n",
        "manual_labels_df = pd.read_csv('/content/manual_labels.csv')\n",
        "\n",
        "# Strip any leading/trailing spaces in column names\n",
        "train_predictions_df.columns = train_predictions_df.columns.str.strip()\n",
        "test_predictions_df.columns = test_predictions_df.columns.str.strip()\n",
        "manual_labels_df.columns = manual_labels_df.columns.str.strip()\n",
        "\n",
        "# Print column names for debugging\n",
        "print(\"Train Predictions DataFrame columns:\", train_predictions_df.columns)\n",
        "print(\"Test Predictions DataFrame columns:\", test_predictions_df.columns)\n",
        "print(\"Manual Labels DataFrame columns:\", manual_labels_df.columns)\n",
        "\n",
        "# Function to evaluate predictions\n",
        "def evaluate_predictions(predictions_df, manual_labels_df):\n",
        "    # Merge predictions with actual labels from manual_labels.csv based on 'Image Name'\n",
        "    merged_df = predictions_df.merge(manual_labels_df[['Image Name', 'License Plate']], on='Image Name', how='left')\n",
        "\n",
        "    # Initialize counters\n",
        "    correct_plate_count = 0\n",
        "    correct_character_count = 0\n",
        "    total_character_count = 0\n",
        "\n",
        "    # Iterate over the merged dataframe to count correct predictions and characters\n",
        "    for _, row in merged_df.iterrows():\n",
        "        predicted_text = str(row['predicted_text']) if pd.notna(row['predicted_text']) else ''\n",
        "        actual_text = str(row['License Plate']) if pd.notna(row['License Plate']) else ''\n",
        "\n",
        "        # Count total characters in actual text\n",
        "        total_character_count += len(actual_text)\n",
        "\n",
        "        # Check if predicted text matches actual text\n",
        "        if predicted_text == actual_text:\n",
        "            correct_plate_count += 1\n",
        "            correct_character_count += len(predicted_text)  # All characters are correct if plate matches\n",
        "        else:\n",
        "            # Count correct characters if plate does not match\n",
        "            correct_character_count += sum(1 for a, b in zip(predicted_text, actual_text) if a == b)\n",
        "\n",
        "\n",
        "# Save results to CSV files\n",
        "train_results_df = pd.DataFrame([train_results])\n",
        "test_results_df = pd.DataFrame([test_results])\n",
        "\n",
        "train_results_df.to_csv('/content/train_evaluation_results.csv', index=False)\n",
        "test_results_df.to_csv('/content/test_evaluation_results.csv', index=False)"
      ],
      "metadata": {
        "id": "yUZIiSLEoIHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import yaml\n",
        "\n",
        "# Paths for files and directories\n",
        "images_path = '/content/dataset/dataset/google_images'\n",
        "output_dir = '/content/processed_data'\n",
        "manual_labels_path = '/content/manual_labels.csv'\n",
        "\n",
        "# Load the manual labels CSV file\n",
        "labels_df = pd.read_csv(manual_labels_path)\n",
        "\n",
        "# Get the image file names from the labels\n",
        "labeled_images = labels_df['Image Name'].tolist()\n",
        "\n",
        "# Separate labeled and unlabeled images\n",
        "all_images = os.listdir(images_path)\n",
        "unlabeled_images = [img for img in all_images if img not in labeled_images]\n",
        "\n",
        "# Split labeled images (300) into 80% train and 20% test\n",
        "train_labels, test_labels = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split unlabeled images (700) into 80-20 train and test\n",
        "train_unlabeled, test_unlabeled = train_test_split(unlabeled_images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the output directories exist\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Move labeled images to train and test directories\n",
        "def copy_images(df, target_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        image_path = os.path.join(images_path, row['Image Name'])\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_images(train_labels, train_dir)\n",
        "copy_images(test_labels, test_dir)\n",
        "\n",
        "# Move unlabeled images to their respective train and test directories\n",
        "def copy_unlabeled_images(image_list, target_dir):\n",
        "    for image in image_list:\n",
        "        image_path = os.path.join(images_path, image)\n",
        "        shutil.copy(image_path, target_dir)\n",
        "\n",
        "copy_unlabeled_images(train_unlabeled, train_dir)\n",
        "copy_unlabeled_images(test_unlabeled, test_dir)\n",
        "\n",
        "# Save the updated labels for train and test sets\n",
        "train_labels.to_csv(os.path.join(train_dir, 'labels.csv'), index=False)\n",
        "test_labels.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)\n",
        "\n",
        "# Define paths for train and test sets in a YAML file\n",
        "data_yaml = {\n",
        "    'path': output_dir,               # Base directory for dataset\n",
        "    'train': 'train',                 # Relative path to train directory\n",
        "    'val': 'test',                    # Relative path to validation directory\n",
        "    'nc': 1,                          # Number of classes\n",
        "    'names': ['license_plate']        # Class names\n",
        "}\n",
        "\n",
        "# Save the YAML file\n",
        "data_yaml_path = '/content/processed_data/data.yaml'\n",
        "with open(data_yaml_path, 'w') as file:\n",
        "    yaml.dump(data_yaml, file)\n",
        "\n",
        "# Train the YOLOv8 model for license plate detection\n",
        "yolo_model_detection = YOLO('yolov8n.pt')\n",
        "yolo_model_detection.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='yolo_plate_detection'\n",
        ")\n",
        "\n",
        "# Train the model for OCR character recognition, using `last.pt` and manual labels\n",
        "yolo_model_ocr = YOLO('last.pt')\n",
        "yolo_model_ocr.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    name='yolo_character_recognition'\n",
        ")\n",
        "\n",
        "# Function to display images with bounding boxes and OCR text\n",
        "def display_image_with_boxes(image_path, boxes, text):\n",
        "    image = cv2.imread(image_path)\n",
        "    for box, t in zip(boxes, text):\n",
        "        x1, y1, x2, y2 = map(int, box[:4])  # Bounding box coordinates\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "        cv2.putText(image, t, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)  # Add OCR text\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Initialize results list to save predictions\n",
        "results_list = []\n",
        "\n",
        "# Evaluating and displaying OCR predictions on the test set\n",
        "def evaluate_and_save_ocr(test_labels, model):\n",
        "    for _, row in test_labels.iterrows():\n",
        "        image_path = os.path.join(test_dir, row['Image Name'])\n",
        "        true_text = row['License Plate'] if pd.notna(row['License Plate']) else 'None'  # Expected license plate text or 'None'\n",
        "\n",
        "        # Get model predictions\n",
        "        results = model(image_path)\n",
        "        predicted_text = results[0].text  # Assuming text prediction function\n",
        "\n",
        "        # Draw bounding boxes and OCR text on the image\n",
        "        bounding_boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
        "        predicted_texts = [predicted_text]  # For display purposes\n",
        "\n",
        "        # Display image with bounding boxes and OCR text\n",
        "        display_image_with_boxes(image_path, bounding_boxes, predicted_texts)\n",
        "\n",
        "        # Append results for saving\n",
        "        results_list.append({\n",
        "            'Image Name': row['Image Name'],\n",
        "            'predicted_text': predicted_text,\n",
        "            'actual_text': true_text\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame and save to CSV\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    results_df.to_csv('/content/test_predictions.csv', index=False)\n",
        "    print(\"Predicted readings saved to /content/test_predictions.csv\")\n",
        "\n",
        "# Run evaluation and save predictions\n",
        "evaluate_and_save_ocr(test_labels, yolo_model_ocr)"
      ],
      "metadata": {
        "id": "gqpJn31qPWfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "from google.colab import files\n",
        "\n",
        "# Load the YOLOv8 model (pre-trained or custom-trained)\n",
        "model = YOLO('/content/last.pt')  # Use last.pt for license plate detection\n",
        "\n",
        "# Function to preprocess the image (resize, enhance, grayscale)\n",
        "def preprocess_image(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply threshold to create a black-and-white effect (binarize the image)\n",
        "    _, binary = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Separate individual characters by dilating the binary image\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated = cv2.dilate(binary, kernel, iterations=1)\n",
        "\n",
        "    # Find contours to separate characters\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    char_images = []\n",
        "    for contour in contours:\n",
        "        # Get bounding box for each contour (character)\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        if w > 5 and h > 15:  # Filter small contours\n",
        "            char_images.append(dilated[y:y+h, x:x+w])  # Crop each character\n",
        "    return dilated, char_images\n",
        "\n",
        "# Function to extract bounding boxes with confidence and class\n",
        "def extract_boxes_with_confidence(results):\n",
        "    boxes = results[0].boxes.xywh.cpu().numpy()  # Bounding box coordinates\n",
        "    confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
        "    classes = results[0].boxes.cls.cpu().numpy()  # Class indices\n",
        "    combined_boxes = [\n",
        "        (x_center, y_center, width, height, conf, cls)\n",
        "        for (x_center, y_center, width, height), conf, cls in zip(boxes, confidences, classes)\n",
        "    ]\n",
        "    return combined_boxes\n",
        "\n",
        "# Function to crop the license plate based on bounding box\n",
        "def crop_license_plate(image, boxes):\n",
        "    for box in boxes:\n",
        "        x_center, y_center, width, height, conf, cls = box\n",
        "        if conf > 0.5:  # Confidence threshold\n",
        "            x1 = int(x_center - width / 2)\n",
        "            y1 = int(y_center - height / 2)\n",
        "            x2 = int(x_center + width / 2)\n",
        "            y2 = int(y_center + height / 2)\n",
        "            cropped_plate = image[y1:y2, x1:x2]\n",
        "            return cropped_plate\n",
        "    return None  # If no plate is detected\n",
        "\n",
        "# Function to perform OCR on the license plate\n",
        "def read_license_plate(image):\n",
        "    reader = easyocr.Reader(['en'], gpu=True)\n",
        "    result = reader.readtext(image)\n",
        "    if result:\n",
        "        text = \" \".join([res[1] for res in result])  # Combine detected text\n",
        "        return text, result\n",
        "    return \"No text detected\", []\n",
        "\n",
        "# Function to display bounding boxes and OCR text on the image\n",
        "def display_image_with_boxes(image, boxes, predicted_texts):\n",
        "    # Draw bounding boxes and OCR text on the image\n",
        "    for box, text in zip(boxes, predicted_texts):\n",
        "        x_center, y_center, width, height, conf, cls = box\n",
        "        if conf > 0.5:  # Only display high-confidence boxes\n",
        "            x1 = int(x_center - width / 2)\n",
        "            y1 = int(y_center - height / 2)\n",
        "            x2 = int(x_center + width / 2)\n",
        "            y2 = int(y_center + height / 2)\n",
        "\n",
        "            # Draw the bounding box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 6)  # Thicker green box\n",
        "\n",
        "            # Make the text bold and large at the top of the image\n",
        "            font_scale = 9  # Larger font size for clarity\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            thickness = 20  # Increased thickness for bold text\n",
        "            text_position = (x1, y1 - 10)  # Positioning text just above the bounding box\n",
        "            cv2.putText(image, text, text_position, font, font_scale, (0, 255, 0), thickness)  # Green bold text\n",
        "\n",
        "    # Convert image from BGR to RGB for display\n",
        "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image with bounding boxes and text\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Step 1: Upload the image from your local computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Read the uploaded image\n",
        "image_path = next(iter(uploaded))  # Get the filename of the uploaded image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Step 3: Preprocess the image\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Step 4: Run YOLOv8 for license plate detection\n",
        "results = model.predict(image, conf=0.5)\n",
        "\n",
        "# Step 5: Extract bounding boxes with confidence and class\n",
        "bounding_boxes = extract_boxes_with_confidence(results)\n",
        "\n",
        "# Step 6: Crop the license plate from the image\n",
        "cropped_plate = crop_license_plate(image, bounding_boxes)\n",
        "if cropped_plate is not None:\n",
        "    # Step 7: Preprocess the cropped license plate (convert to grayscale and enhance)\n",
        "    preprocessed_plate, char_images = preprocess_image(cropped_plate)\n",
        "\n",
        "    # Step 8: Perform OCR to read the license plate text\n",
        "    detected_text, ocr_results = read_license_plate(preprocessed_plate)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Detected License Plate Text:\", detected_text)\n",
        "\n",
        "    # Step 9: Display the image with bounding boxes and OCR text\n",
        "    display_image_with_boxes(image, bounding_boxes, [detected_text])\n",
        "\n",
        "else:\n",
        "    print(\"No license plate detected in the image.\")"
      ],
      "metadata": {
        "id": "dd2BBsRo5sGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "from google.colab import files\n",
        "\n",
        "# Load the YOLOv8 model (pre-trained or custom-trained)\n",
        "model = YOLO('/content/last.pt')  # Use last.pt for license plate detection\n",
        "\n",
        "# Function to preprocess the image (resize, enhance, grayscale)\n",
        "def preprocess_image(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Apply threshold to create a black-and-white effect (binarize the image)\n",
        "    _, binary = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Separate individual characters by dilating the binary image\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    dilated = cv2.dilate(binary, kernel, iterations=1)\n",
        "\n",
        "    return dilated\n",
        "\n",
        "# Function to extract bounding boxes with confidence and class\n",
        "def extract_boxes_with_confidence(results):\n",
        "    boxes = results[0].boxes.xywh.cpu().numpy()  # Bounding box coordinates\n",
        "    confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
        "    classes = results[0].boxes.cls.cpu().numpy()  # Class indices\n",
        "    combined_boxes = [\n",
        "        (x_center, y_center, width, height, conf, cls)\n",
        "        for (x_center, y_center, width, height), conf, cls in zip(boxes, confidences, classes)\n",
        "    ]\n",
        "    return combined_boxes\n",
        "\n",
        "# Function to crop the license plate based on bounding box\n",
        "def crop_license_plate(image, boxes):\n",
        "    for box in boxes:\n",
        "        x_center, y_center, width, height, conf, cls = box\n",
        "        if conf > 0.5:  # Confidence threshold\n",
        "            x1 = int(x_center - width / 2)\n",
        "            y1 = int(y_center - height / 2)\n",
        "            x2 = int(x_center + width / 2)\n",
        "            y2 = int(y_center + height / 2)\n",
        "            cropped_plate = image[y1:y2, x1:x2]\n",
        "            return cropped_plate\n",
        "    return None  # If no plate is detected\n",
        "\n",
        "# Function to perform OCR on the license plate\n",
        "def read_license_plate(image):\n",
        "    reader = easyocr.Reader(['en'], gpu=True)\n",
        "    result = reader.readtext(image)\n",
        "    if result:\n",
        "        text = \" \".join([res[1] for res in result])  # Combine detected text\n",
        "        return text\n",
        "    return \"No text detected\"\n",
        "\n",
        "# Step 1: Upload the image from your local computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Read the uploaded image\n",
        "image_path = next(iter(uploaded))  # Get the filename of the uploaded image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Step 3: Preprocess the image\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Step 4: Run YOLOv8 for license plate detection\n",
        "results = model.predict(image, conf=0.5)\n",
        "\n",
        "# Step 5: Extract bounding boxes with confidence and class\n",
        "bounding_boxes = extract_boxes_with_confidence(results)\n",
        "\n",
        "# Step 6: Crop the license plate from the image\n",
        "cropped_plate = crop_license_plate(image, bounding_boxes)\n",
        "if cropped_plate is not None:\n",
        "    # Step 7: Preprocess the cropped license plate (convert to grayscale and enhance)\n",
        "    preprocessed_plate = preprocess_image(cropped_plate)\n",
        "\n",
        "    # Step 8: Perform OCR to read the license plate text\n",
        "    detected_text = read_license_plate(preprocessed_plate)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Detected License Plate Text:\", detected_text)\n",
        "\n",
        "    # Step 9: Show original image with bounding boxes\n",
        "    for box in bounding_boxes:\n",
        "        x_center, y_center, width, height, conf, cls = box\n",
        "        if conf > 0.5:  # Only display high-confidence boxes\n",
        "            x1 = int(x_center - width / 2)\n",
        "            y1 = int(y_center - height / 2)\n",
        "            x2 = int(x_center + width / 2)\n",
        "            y2 = int(y_center + height / 2)\n",
        "            cv2.rectangle(rgb_image, (x1, y1), (x2, y2), (0, 255, 0), 4)  # Bold bounding box line\n",
        "            cv2.putText(rgb_image, detected_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)  # Text on the image\n",
        "\n",
        "    # Display the original image with bounding boxes and cropped plate\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Original image with bounding box\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Original Image with Bounding Box\")\n",
        "    plt.imshow(rgb_image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Grayscale cropped license plate (enhanced with character separation)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Grayscale Cropped License Plate with Character Separation\")\n",
        "    plt.imshow(preprocessed_plate, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"No license plate detected in the image.\")"
      ],
      "metadata": {
        "id": "m5BAzBs48sGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}